{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import array\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle5\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, log_loss, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-connecticut",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/your_path/KSC_DB renew_20210612_brief.csv', encoding='CP949') # You should edit the file path\n",
    "\n",
    "# Remove NaN rows\n",
    "data = data.dropna(how = 'all').reset_index(drop = True)\n",
    "# Select target patients\n",
    "data = data.loc[data['Study_yes'] == 1].reset_index(drop=True)\n",
    "# Make new ID as (DCC id)_(patient id)\n",
    "data['ID'] = data[\"DCC_ID\"].astype(int).astype(str) + '_' + data[\"patient_ID\"].astype(int).astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-october",
   "metadata": {},
   "source": [
    "## If you want to use SMOTE for handling class imbalance problem, set this True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE_ON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-transparency",
   "metadata": {},
   "source": [
    "## Exp setting\n",
    "\n",
    "### - Exp 1 setting ( 0 vs (1/2/3/4) )\n",
    "### - Exp 2 setting ( 0 vs (1/2/3/4/9) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use exp 2 setting, type 'exp2'\n",
    "target_exp = 'exp1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-headquarters",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if target_exp == 'exp1':\n",
    "    data_target = data.loc[data['outcome'].isin([0,1,2,3,4])].reset_index(drop=True)\n",
    "elif target_exp == 'exp2':\n",
    "    data_target = data.loc[data['outcome'].isin([0,1,2,3,4,9])].reset_index(drop=True)\n",
    "else:\n",
    "    print('you should type exp1 or exp2 for target_exp')\n",
    "    \n",
    "data_target['outcome'] = data_target['outcome'].astype(int)\n",
    "data_target_effective = copy.deepcopy(data_target)\n",
    "data_effective = []\n",
    "for i in data_target['outcome']:\n",
    "    if i == 0:\n",
    "        data_effective.append(0)\n",
    "    else:\n",
    "        data_effective.append(1)\n",
    "data_target_effective['label'] = data_effective\n",
    "data_target_effective_clinical = data_target_effective[['ID', 'label', 'sex', 'age','AF_duration', 'latest_AAD', 'New-CVASc', 'LVEF', 'LA', 'BMI']]\n",
    "# Drop row if it has any NaN features\n",
    "data_target_effective_clinical = data_target_effective_clinical.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-latino",
   "metadata": {},
   "source": [
    "### Number of patients by each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label 0 : ' + str(len(data_target_effective_clinical.loc[data_target_effective_clinical['label'] == 0])))\n",
    "print('label 1 : ' + str(len(data_target_effective_clinical.loc[data_target_effective_clinical['label'] == 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-dancing",
   "metadata": {},
   "source": [
    "## Logist regression using all features without feature pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_target_effective_clinical.values[:,2:], \n",
    "                                                    data_target_effective_clinical['label'].values, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "if SMOTE_ON is True:\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, penalty='none')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_tr = model.predict(X_train)\n",
    "print('train_loss')\n",
    "print(log_loss(y_train, (y_pred_tr > 0.5)*1.0))\n",
    "print('test_loss')\n",
    "print(log_loss(y_test, (y_pred > 0.5)*1.0))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, (y_pred > 0.5)*1.0).ravel()\n",
    "acc = (tp + tn) / (tp + fp + fn + tn) * 100\n",
    "sen = tp / (tp + fn) * 100\n",
    "spe = tn / (tn + fp) * 100\n",
    "pr = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = (2*pr*recall) / (pr + recall)\n",
    "y_pred = (y_pred > 0.5)*1.0\n",
    "\n",
    "print('auroc : ' + str(roc_auc_score(y_test, y_pred)))\n",
    "print('sen : ' + str(sen))\n",
    "print('spe : ' + str(spe))\n",
    "print('f1 : ' + str(f1))\n",
    "print('auprc : ' + str(average_precision_score(y_test, y_pred)))\n",
    "# print(str(roc_auc_score(y_test, y_pred)) + ',' + str(sen) + ',' + str(spe) + ',' + str(f1) + ',' + str(average_precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-bernard",
   "metadata": {},
   "source": [
    "## Convert a continuous feature to categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Age\n",
    "data_target_effective_clinical['age'] = (data_target_effective_clinical['age'] >= 58)*1.0\n",
    "\n",
    "# ### AF duration\n",
    "# new_values = []\n",
    "# for i in data_target_effective_clinical['AF_duration']:\n",
    "#     if np.isnan(i):\n",
    "#         new_values.append(99.0)\n",
    "#     elif i >= 12:\n",
    "#         new_values.append(1.0)\n",
    "#     else:\n",
    "#         new_values.append(0.0)\n",
    "# data_target_effective_clinical['AF_duration'] = new_values\n",
    "\n",
    "### latest AAD\n",
    "new_values = []\n",
    "for i in data_target_effective_clinical['latest_AAD']:\n",
    "    if i == 5:\n",
    "        new_values.append(1.0)\n",
    "    else:\n",
    "        new_values.append(0.0)\n",
    "data_target_effective_clinical['latest_AAD'] = new_values\n",
    "\n",
    "# ### hs-CRP\n",
    "# new_values = []\n",
    "# for i in data_target_effective_clinical['hs-CRP']:\n",
    "#     if np.isnan(i):\n",
    "#         new_values.append(99.0)\n",
    "#     elif i >= 0.1:\n",
    "#         new_values.append(1.0)\n",
    "#     else:\n",
    "#         new_values.append(0.0)\n",
    "# data_target_effective_clinical['hs-CRP'] = new_values\n",
    "\n",
    "### New-CVASc\n",
    "new_values = []\n",
    "for i in data_target_effective_clinical['New-CVASc']:\n",
    "    if np.isnan(i):\n",
    "        new_values.append(99.0)\n",
    "    elif i >= 2.0:\n",
    "        new_values.append(1.0)\n",
    "    else:\n",
    "        new_values.append(0.0)\n",
    "data_target_effective_clinical['New-CVASc'] = new_values\n",
    "\n",
    "# ### LVEF\n",
    "# new_values = []\n",
    "# for i in data_target_effective_clinical['LVEF']:\n",
    "#     if np.isnan(i):\n",
    "#         new_values.append(99.0)\n",
    "#     elif i >= 40.0:\n",
    "#         new_values.append(1.0)\n",
    "#     else:\n",
    "#         new_values.append(0.0)\n",
    "# data_target_effective_clinical['LVEF'] = new_values\n",
    "\n",
    "### LA\n",
    "new_values = []\n",
    "for i in data_target_effective_clinical['LA']:\n",
    "    if i >= 50.0:\n",
    "        new_values.append(1.0)\n",
    "    else:\n",
    "        new_values.append(0.0)\n",
    "data_target_effective_clinical['LA'] = new_values\n",
    "\n",
    "### BMI\n",
    "new_values = []\n",
    "for i in data_target_effective_clinical['BMI']:\n",
    "    bmi = float(i)\n",
    "    if bmi >= 28.0:\n",
    "        new_values.append(1.0)\n",
    "    else:\n",
    "        new_values.append(0.0)\n",
    "data_target_effective_clinical['BMI'] = new_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-deployment",
   "metadata": {},
   "source": [
    "## Logist regression using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-cleveland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_target_effective_clinical.values[:,2:], \n",
    "                                                    data_target_effective_clinical['label'].values, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "if SMOTE_ON is True:\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, penalty='none')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_tr = model.predict(X_train)\n",
    "print('train_loss')\n",
    "print(log_loss(y_train, (y_pred_tr > 0.5)*1.0))\n",
    "print('test_loss')\n",
    "print(log_loss(y_test, (y_pred > 0.5)*1.0))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, (y_pred > 0.5)*1.0).ravel()\n",
    "acc = (tp + tn) / (tp + fp + fn + tn) * 100\n",
    "sen = tp / (tp + fn) * 100\n",
    "spe = tn / (tn + fp) * 100\n",
    "pr = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = (2*pr*recall) / (pr + recall)\n",
    "y_pred = (y_pred > 0.5)*1.0\n",
    "\n",
    "print('auroc : ' + str(roc_auc_score(y_test, y_pred)))\n",
    "print('sen : ' + str(sen))\n",
    "print('spe : ' + str(spe))\n",
    "print('f1 : ' + str(f1))\n",
    "print('auprc : ' + str(average_precision_score(y_test, y_pred)))\n",
    "# print(str(roc_auc_score(y_test, y_pred)) + ',' + str(sen) + ',' + str(spe) + ',' + str(f1) + ',' + str(average_precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-fraud",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-choir",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sfs = SequentialFeatureSelector(LogisticRegression(C=1000), n_features_to_select=3, direction='forward').fit(X_train,y_train)\n",
    "data_target_effective_clinical.columns[2:][sfs.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-living",
   "metadata": {},
   "source": [
    "## Logistic regression using selected features\n",
    "\n",
    "### they are 'age', 'LVEF', 'LA', 'AF_duration', 'latest_AAD' in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tt_target_effective_clinical[['age', 'LVEF', 'LA', 'AF_duration', 'latest_AAD']].values, \n",
    "                                                    tt_target_effective_clinical['label'].values, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "if SMOTE_ON is True:\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, penalty='none')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_tr = model.predict(X_train)\n",
    "print('train_loss')\n",
    "print(log_loss(y_train, (y_pred_tr > 0.5)*1.0))\n",
    "print('test_loss')\n",
    "print(log_loss(y_test, (y_pred > 0.5)*1.0))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, (y_pred > 0.5)*1.0).ravel()\n",
    "acc = (tp + tn) / (tp + fp + fn + tn) * 100\n",
    "sen = tp / (tp + fn) * 100\n",
    "spe = tn / (tn + fp) * 100\n",
    "pr = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = (2*pr*recall) / (pr + recall)\n",
    "y_pred = (y_pred > 0.5)*1.0\n",
    "\n",
    "print('auroc : ' + str(roc_auc_score(y_test, y_pred)))\n",
    "print('sen : ' + str(sen))\n",
    "print('spe : ' + str(spe))\n",
    "print('f1 : ' + str(f1))\n",
    "print('auprc : ' + str(average_precision_score(y_test, y_pred)))\n",
    "# print(str(roc_auc_score(y_test, y_pred)) + ',' + str(sen) + ',' + str(spe) + ',' + str(f1) + ',' + str(average_precision_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
